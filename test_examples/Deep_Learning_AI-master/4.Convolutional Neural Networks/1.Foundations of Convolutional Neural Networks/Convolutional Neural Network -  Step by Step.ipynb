{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PEIM001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 9.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (pad,pad))\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[1,1] = [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] = [[2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a88b0c668>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[1,1] =\", x[1,1])\n",
    "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single step of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "\n",
    "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    \n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    \n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume\n",
    "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                  # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]      # Select ith training example's padded activation\n",
    "        for h in range(n_H):            # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):        # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):    # loop over channels (= #filters) of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])\n",
    "                                          \n",
    "    # Making sure the output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 1.3709261862396385\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):                   # loop over the training examples\n",
    "        for h in range(n_H):             # loop on the vertical axis of the output volume\n",
    "            for w in range(n_W):         # loop on the horizontal axis of the output volume\n",
    "                for c in range (n_C):    # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A = [[[[2.18557541 2.18557541 2.18557541]]]\n",
      "\n",
      "\n",
      " [[[2.18557541 2.18557541 2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[0.01450467 0.01450467 0.01450467]]]\n",
      "\n",
      "\n",
      " [[[0.01450467 0.01450467 0.01450467]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        da_prev_pad = dA_prev_pad[i]\n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpaded da_prev_pad\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1.4524377775388075\n",
      "dW_mean = 428.0840996407307\n",
      "db_mean = 219.34818979834262\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling - backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "\n",
    "    mask = x == np.max(x)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2,3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pooling - backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "\n",
    "    # Retrieve dimensions from shape\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value\n",
    "    a = np.ones(shape) * average\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2,2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \n",
    "    # Retrieve information from cache\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    stride = hparameters['stride']\n",
    "    f = hparameters['f']\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros\n",
    "    dA_prev = np.zeros(A_prev.shape)                           \n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev\n",
    "        a_prev = A_prev[i]\n",
    "        \n",
    "        for h in range(n_H):                   # loop on the vertical axis\n",
    "            for w in range(n_W):               # loop on the horizontal axis\n",
    "                for c in range(n_C):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        \n",
    "                        # Create the mask from a_prev_slice (≈1 line)\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        \n",
    "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # Get the value a from dA\n",
    "                        da = dA[i, h, w, c]\n",
    "                        \n",
    "                        # Define the shape of the filter as fxf\n",
    "                        shape = (f, f)\n",
    "                        \n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
