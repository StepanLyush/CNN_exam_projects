{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PEIM001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 25484.49it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.09.70', '1970-09-10'),\n",
       " ('4/28/90', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('tuesday july 8 2008', '2008-07-08'),\n",
       " ('08 sep 1999', '1999-09-08'),\n",
       " ('1 jan 1981', '1981-01-01'),\n",
       " ('monday may 22 1995', '1995-05-22')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\"\n",
    "    s_prev = repeator(s_prev)\n",
    "    \n",
    "    # Use concatenator to concatenate a and s_prev on the last axis\n",
    "    concat = concatenator([a, s_prev])\n",
    "    \n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e\n",
    "    e = densor1(concat)\n",
    "    \n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies\n",
    "    energies = densor2(e)\n",
    "    \n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\"\n",
    "    alphas = activator(energies)\n",
    "    \n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell\n",
    "    context = dotor([alphas, a])\n",
    "        \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "      \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state]\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s,c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2800/10000 [=======>......................] - ETA: 14:31 - loss: 24.0342 - dense_3_loss: 2.3957 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.1400 - dense_3_acc_3: 0.1000 - dense_3_acc_4: 0.0000e+00 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0900 - dense_3_acc_7: 0.0000e+00 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.10 - ETA: 7:14 - loss: 23.8318 - dense_3_loss: 2.4042 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0700 - dense_3_acc_3: 0.0500 - dense_3_acc_4: 0.5000 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0450 - dense_3_acc_7: 0.5000 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.0500         - ETA: 4:49 - loss: 23.6346 - dense_3_loss: 2.4215 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0467 - dense_3_acc_3: 0.0333 - dense_3_acc_4: 0.6667 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0300 - dense_3_acc_7: 0.6667 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.033 - ETA: 3:37 - loss: 23.3835 - dense_3_loss: 2.4527 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0350 - dense_3_acc_3: 0.0250 - dense_3_acc_4: 0.7500 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0225 - dense_3_acc_7: 0.7500 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.025 - ETA: 2:53 - loss: 23.1218 - dense_3_loss: 2.5262 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0280 - dense_3_acc_3: 0.0200 - dense_3_acc_4: 0.8000 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0180 - dense_3_acc_7: 0.8000 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.020 - ETA: 2:24 - loss: 22.9809 - dense_3_loss: 2.6208 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0233 - dense_3_acc_3: 0.0167 - dense_3_acc_4: 0.8333 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.8333 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.016 - ETA: 2:03 - loss: 22.7901 - dense_3_loss: 2.6703 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0000e+00 - dense_3_acc_2: 0.0200 - dense_3_acc_3: 0.0143 - dense_3_acc_4: 0.8571 - dense_3_acc_5: 0.0000e+00 - dense_3_acc_6: 0.0129 - dense_3_acc_7: 0.8571 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.014 - ETA: 1:47 - loss: 22.6487 - dense_3_loss: 2.7046 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0500 - dense_3_acc_2: 0.0450 - dense_3_acc_3: 0.0263 - dense_3_acc_4: 0.7525 - dense_3_acc_5: 0.0913 - dense_3_acc_6: 0.0188 - dense_3_acc_7: 0.7500 - dense_3_acc_8: 0.0350 - dense_3_acc_9: 0.0225            - ETA: 1:35 - loss: 22.5497 - dense_3_loss: 2.7205 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.0878 - dense_3_acc_2: 0.0589 - dense_3_acc_3: 0.0311 - dense_3_acc_4: 0.6689 - dense_3_acc_5: 0.1678 - dense_3_acc_6: 0.0244 - dense_3_acc_7: 0.6667 - dense_3_acc_8: 0.0644 - dense_3_acc_9: 0.030 - ETA: 1:25 - loss: 22.4520 - dense_3_loss: 2.7296 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1190 - dense_3_acc_2: 0.0750 - dense_3_acc_3: 0.0420 - dense_3_acc_4: 0.6020 - dense_3_acc_5: 0.2190 - dense_3_acc_6: 0.0340 - dense_3_acc_7: 0.6000 - dense_3_acc_8: 0.0870 - dense_3_acc_9: 0.036 - ETA: 1:17 - loss: 22.3657 - dense_3_loss: 2.7278 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1482 - dense_3_acc_2: 0.0909 - dense_3_acc_3: 0.0491 - dense_3_acc_4: 0.5473 - dense_3_acc_5: 0.2673 - dense_3_acc_6: 0.0336 - dense_3_acc_7: 0.5455 - dense_3_acc_8: 0.0991 - dense_3_acc_9: 0.043 - ETA: 1:11 - loss: 22.2991 - dense_3_loss: 2.7329 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1700 - dense_3_acc_2: 0.0992 - dense_3_acc_3: 0.0517 - dense_3_acc_4: 0.5025 - dense_3_acc_5: 0.3092 - dense_3_acc_6: 0.0342 - dense_3_acc_7: 0.5225 - dense_3_acc_8: 0.1033 - dense_3_acc_9: 0.042 - ETA: 1:05 - loss: 22.2299 - dense_3_loss: 2.7467 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1808 - dense_3_acc_2: 0.1015 - dense_3_acc_3: 0.0508 - dense_3_acc_4: 0.5385 - dense_3_acc_5: 0.2854 - dense_3_acc_6: 0.0315 - dense_3_acc_7: 0.5592 - dense_3_acc_8: 0.0954 - dense_3_acc_9: 0.039 - ETA: 1:00 - loss: 22.1429 - dense_3_loss: 2.7463 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1857 - dense_3_acc_2: 0.0943 - dense_3_acc_3: 0.0471 - dense_3_acc_4: 0.5714 - dense_3_acc_5: 0.2650 - dense_3_acc_6: 0.0293 - dense_3_acc_7: 0.5907 - dense_3_acc_8: 0.0886 - dense_3_acc_9: 0.036 - ETA: 56s - loss: 22.0832 - dense_3_loss: 2.7627 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1787 - dense_3_acc_2: 0.0880 - dense_3_acc_3: 0.0440 - dense_3_acc_4: 0.6000 - dense_3_acc_5: 0.2473 - dense_3_acc_6: 0.0273 - dense_3_acc_7: 0.6180 - dense_3_acc_8: 0.0827 - dense_3_acc_9: 0.034 - ETA: 52s - loss: 22.0274 - dense_3_loss: 2.7765 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1725 - dense_3_acc_2: 0.0825 - dense_3_acc_3: 0.0412 - dense_3_acc_4: 0.6250 - dense_3_acc_5: 0.2319 - dense_3_acc_6: 0.0256 - dense_3_acc_7: 0.6419 - dense_3_acc_8: 0.0775 - dense_3_acc_9: 0.03 - ETA: 49s - loss: 21.9661 - dense_3_loss: 2.7798 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1735 - dense_3_acc_2: 0.0776 - dense_3_acc_3: 0.0388 - dense_3_acc_4: 0.6471 - dense_3_acc_5: 0.2182 - dense_3_acc_6: 0.0241 - dense_3_acc_7: 0.6629 - dense_3_acc_8: 0.0729 - dense_3_acc_9: 0.03 - ETA: 46s - loss: 21.8942 - dense_3_loss: 2.7802 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1867 - dense_3_acc_2: 0.0733 - dense_3_acc_3: 0.0367 - dense_3_acc_4: 0.6667 - dense_3_acc_5: 0.2061 - dense_3_acc_6: 0.0228 - dense_3_acc_7: 0.6817 - dense_3_acc_8: 0.0689 - dense_3_acc_9: 0.02 - ETA: 44s - loss: 21.8434 - dense_3_loss: 2.7834 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.1989 - dense_3_acc_2: 0.0795 - dense_3_acc_3: 0.0347 - dense_3_acc_4: 0.6842 - dense_3_acc_5: 0.1953 - dense_3_acc_6: 0.0216 - dense_3_acc_7: 0.6984 - dense_3_acc_8: 0.0653 - dense_3_acc_9: 0.02 - ETA: 41s - loss: 21.7893 - dense_3_loss: 2.7820 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2100 - dense_3_acc_2: 0.0855 - dense_3_acc_3: 0.0345 - dense_3_acc_4: 0.7000 - dense_3_acc_5: 0.1855 - dense_3_acc_6: 0.0205 - dense_3_acc_7: 0.7135 - dense_3_acc_8: 0.0620 - dense_3_acc_9: 0.02 - ETA: 39s - loss: 21.7492 - dense_3_loss: 2.7886 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2186 - dense_3_acc_2: 0.0938 - dense_3_acc_3: 0.0381 - dense_3_acc_4: 0.7143 - dense_3_acc_5: 0.1767 - dense_3_acc_6: 0.0195 - dense_3_acc_7: 0.7271 - dense_3_acc_8: 0.0590 - dense_3_acc_9: 0.02 - ETA: 37s - loss: 21.6946 - dense_3_loss: 2.7845 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2236 - dense_3_acc_2: 0.0973 - dense_3_acc_3: 0.0432 - dense_3_acc_4: 0.7082 - dense_3_acc_5: 0.1686 - dense_3_acc_6: 0.0186 - dense_3_acc_7: 0.7395 - dense_3_acc_8: 0.0564 - dense_3_acc_9: 0.02 - ETA: 35s - loss: 21.6465 - dense_3_loss: 2.7817 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2283 - dense_3_acc_2: 0.1004 - dense_3_acc_3: 0.0448 - dense_3_acc_4: 0.6796 - dense_3_acc_5: 0.1613 - dense_3_acc_6: 0.0178 - dense_3_acc_7: 0.7509 - dense_3_acc_8: 0.0539 - dense_3_acc_9: 0.02 - ETA: 33s - loss: 21.6027 - dense_3_loss: 2.7823 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2437 - dense_3_acc_2: 0.1029 - dense_3_acc_3: 0.0467 - dense_3_acc_4: 0.6513 - dense_3_acc_5: 0.1858 - dense_3_acc_6: 0.0171 - dense_3_acc_7: 0.7613 - dense_3_acc_8: 0.0517 - dense_3_acc_9: 0.02 - ETA: 32s - loss: 21.5535 - dense_3_loss: 2.7783 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2612 - dense_3_acc_2: 0.1060 - dense_3_acc_3: 0.0496 - dense_3_acc_4: 0.6252 - dense_3_acc_5: 0.2080 - dense_3_acc_6: 0.0180 - dense_3_acc_7: 0.7708 - dense_3_acc_8: 0.0496 - dense_3_acc_9: 0.02 - ETA: 30s - loss: 21.5065 - dense_3_loss: 2.7772 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2735 - dense_3_acc_2: 0.1112 - dense_3_acc_3: 0.0508 - dense_3_acc_4: 0.6012 - dense_3_acc_5: 0.2004 - dense_3_acc_6: 0.0173 - dense_3_acc_7: 0.7796 - dense_3_acc_8: 0.0477 - dense_3_acc_9: 0.02 - ETA: 29s - loss: 21.4652 - dense_3_loss: 2.7751 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2867 - dense_3_acc_2: 0.1189 - dense_3_acc_3: 0.0511 - dense_3_acc_4: 0.6159 - dense_3_acc_5: 0.1930 - dense_3_acc_6: 0.0167 - dense_3_acc_7: 0.7878 - dense_3_acc_8: 0.0459 - dense_3_acc_9: 0.02 - ETA: 28s - loss: 21.4179 - dense_3_loss: 2.7693 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.2993 - dense_3_acc_2: 0.1225 - dense_3_acc_3: 0.0521 - dense_3_acc_4: 0.6296 - dense_3_acc_5: 0.1861 - dense_3_acc_6: 0.0161 - dense_3_acc_7: 0.7954 - dense_3_acc_8: 0.0443 - dense_3_acc_9: 0.0293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5700/10000 [================>.............] - ETA: 27s - loss: 21.3792 - dense_3_loss: 2.7684 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3124 - dense_3_acc_2: 0.1252 - dense_3_acc_3: 0.0531 - dense_3_acc_4: 0.6424 - dense_3_acc_5: 0.1797 - dense_3_acc_6: 0.0155 - dense_3_acc_7: 0.8024 - dense_3_acc_8: 0.0428 - dense_3_acc_9: 0.03 - ETA: 26s - loss: 21.3245 - dense_3_loss: 2.7677 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3247 - dense_3_acc_2: 0.1297 - dense_3_acc_3: 0.0543 - dense_3_acc_4: 0.6543 - dense_3_acc_5: 0.1737 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.8090 - dense_3_acc_8: 0.0413 - dense_3_acc_9: 0.02 - ETA: 24s - loss: 21.2822 - dense_3_loss: 2.7663 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3332 - dense_3_acc_2: 0.1303 - dense_3_acc_3: 0.0565 - dense_3_acc_4: 0.6655 - dense_3_acc_5: 0.1681 - dense_3_acc_6: 0.0145 - dense_3_acc_7: 0.8152 - dense_3_acc_8: 0.0400 - dense_3_acc_9: 0.02 - ETA: 23s - loss: 21.2293 - dense_3_loss: 2.7640 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3453 - dense_3_acc_2: 0.1347 - dense_3_acc_3: 0.0547 - dense_3_acc_4: 0.6759 - dense_3_acc_5: 0.1628 - dense_3_acc_6: 0.0141 - dense_3_acc_7: 0.8209 - dense_3_acc_8: 0.0388 - dense_3_acc_9: 0.03 - ETA: 23s - loss: 21.1875 - dense_3_loss: 2.7624 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3545 - dense_3_acc_2: 0.1370 - dense_3_acc_3: 0.0530 - dense_3_acc_4: 0.6858 - dense_3_acc_5: 0.1579 - dense_3_acc_6: 0.0136 - dense_3_acc_7: 0.8264 - dense_3_acc_8: 0.0409 - dense_3_acc_9: 0.03 - ETA: 22s - loss: 21.1526 - dense_3_loss: 2.7617 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3624 - dense_3_acc_2: 0.1400 - dense_3_acc_3: 0.0515 - dense_3_acc_4: 0.6950 - dense_3_acc_5: 0.1532 - dense_3_acc_6: 0.0132 - dense_3_acc_7: 0.8315 - dense_3_acc_8: 0.0424 - dense_3_acc_9: 0.03 - ETA: 21s - loss: 21.1122 - dense_3_loss: 2.7618 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3700 - dense_3_acc_2: 0.1420 - dense_3_acc_3: 0.0517 - dense_3_acc_4: 0.7037 - dense_3_acc_5: 0.1489 - dense_3_acc_6: 0.0129 - dense_3_acc_7: 0.8363 - dense_3_acc_8: 0.0411 - dense_3_acc_9: 0.03 - ETA: 20s - loss: 21.0690 - dense_3_loss: 2.7593 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3758 - dense_3_acc_2: 0.1456 - dense_3_acc_3: 0.0525 - dense_3_acc_4: 0.7119 - dense_3_acc_5: 0.1447 - dense_3_acc_6: 0.0125 - dense_3_acc_7: 0.8408 - dense_3_acc_8: 0.0400 - dense_3_acc_9: 0.03 - ETA: 19s - loss: 21.0205 - dense_3_loss: 2.7569 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3814 - dense_3_acc_2: 0.1486 - dense_3_acc_3: 0.0543 - dense_3_acc_4: 0.7197 - dense_3_acc_5: 0.1408 - dense_3_acc_6: 0.0122 - dense_3_acc_7: 0.8451 - dense_3_acc_8: 0.0449 - dense_3_acc_9: 0.03 - ETA: 19s - loss: 20.9722 - dense_3_loss: 2.7567 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3882 - dense_3_acc_2: 0.1532 - dense_3_acc_3: 0.0550 - dense_3_acc_4: 0.7271 - dense_3_acc_5: 0.1371 - dense_3_acc_6: 0.0118 - dense_3_acc_7: 0.8492 - dense_3_acc_8: 0.0524 - dense_3_acc_9: 0.03 - ETA: 18s - loss: 20.9309 - dense_3_loss: 2.7609 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3926 - dense_3_acc_2: 0.1544 - dense_3_acc_3: 0.0562 - dense_3_acc_4: 0.7341 - dense_3_acc_5: 0.1336 - dense_3_acc_6: 0.0115 - dense_3_acc_7: 0.8531 - dense_3_acc_8: 0.0526 - dense_3_acc_9: 0.03 - ETA: 17s - loss: 20.8901 - dense_3_loss: 2.7611 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.3972 - dense_3_acc_2: 0.1545 - dense_3_acc_3: 0.0565 - dense_3_acc_4: 0.7408 - dense_3_acc_5: 0.1302 - dense_3_acc_6: 0.0112 - dense_3_acc_7: 0.8568 - dense_3_acc_8: 0.0528 - dense_3_acc_9: 0.04 - ETA: 17s - loss: 20.8431 - dense_3_loss: 2.7638 - dense_3_acc: 0.0000e+00 - dense_3_acc_1: 0.4049 - dense_3_acc_2: 0.1583 - dense_3_acc_3: 0.0580 - dense_3_acc_4: 0.7471 - dense_3_acc_5: 0.1271 - dense_3_acc_6: 0.0110 - dense_3_acc_7: 0.8500 - dense_3_acc_8: 0.0595 - dense_3_acc_9: 0.04 - ETA: 16s - loss: 20.8017 - dense_3_loss: 2.7636 - dense_3_acc: 0.0012 - dense_3_acc_1: 0.4093 - dense_3_acc_2: 0.1602 - dense_3_acc_3: 0.0583 - dense_3_acc_4: 0.7531 - dense_3_acc_5: 0.1240 - dense_3_acc_6: 0.0107 - dense_3_acc_7: 0.8486 - dense_3_acc_8: 0.0662 - dense_3_acc_9: 0.0445   - ETA: 16s - loss: 20.7612 - dense_3_loss: 2.7639 - dense_3_acc: 0.0133 - dense_3_acc_1: 0.4137 - dense_3_acc_2: 0.1616 - dense_3_acc_3: 0.0588 - dense_3_acc_4: 0.7588 - dense_3_acc_5: 0.1212 - dense_3_acc_6: 0.0105 - dense_3_acc_7: 0.8521 - dense_3_acc_8: 0.0651 - dense_3_acc_9: 0.04 - ETA: 15s - loss: 20.7169 - dense_3_loss: 2.7681 - dense_3_acc: 0.0280 - dense_3_acc_1: 0.4193 - dense_3_acc_2: 0.1627 - dense_3_acc_3: 0.0593 - dense_3_acc_4: 0.7643 - dense_3_acc_5: 0.1184 - dense_3_acc_6: 0.0102 - dense_3_acc_7: 0.8555 - dense_3_acc_8: 0.0643 - dense_3_acc_9: 0.04 - ETA: 15s - loss: 20.6616 - dense_3_loss: 2.7642 - dense_3_acc: 0.0444 - dense_3_acc_1: 0.4271 - dense_3_acc_2: 0.1664 - dense_3_acc_3: 0.0593 - dense_3_acc_4: 0.7696 - dense_3_acc_5: 0.1158 - dense_3_acc_6: 0.0100 - dense_3_acc_7: 0.8587 - dense_3_acc_8: 0.0693 - dense_3_acc_9: 0.04 - ETA: 14s - loss: 20.6204 - dense_3_loss: 2.7636 - dense_3_acc: 0.0559 - dense_3_acc_1: 0.4302 - dense_3_acc_2: 0.1683 - dense_3_acc_3: 0.0598 - dense_3_acc_4: 0.7746 - dense_3_acc_5: 0.1133 - dense_3_acc_6: 0.0098 - dense_3_acc_7: 0.8617 - dense_3_acc_8: 0.0741 - dense_3_acc_9: 0.05 - ETA: 14s - loss: 20.5733 - dense_3_loss: 2.7621 - dense_3_acc: 0.0679 - dense_3_acc_1: 0.4343 - dense_3_acc_2: 0.1698 - dense_3_acc_3: 0.0613 - dense_3_acc_4: 0.7794 - dense_3_acc_5: 0.1109 - dense_3_acc_6: 0.0096 - dense_3_acc_7: 0.8647 - dense_3_acc_8: 0.0747 - dense_3_acc_9: 0.05 - ETA: 13s - loss: 20.5281 - dense_3_loss: 2.7625 - dense_3_acc: 0.0815 - dense_3_acc_1: 0.4402 - dense_3_acc_2: 0.1721 - dense_3_acc_3: 0.0617 - dense_3_acc_4: 0.7840 - dense_3_acc_5: 0.1085 - dense_3_acc_6: 0.0094 - dense_3_acc_7: 0.8675 - dense_3_acc_8: 0.0763 - dense_3_acc_9: 0.05 - ETA: 13s - loss: 20.4849 - dense_3_loss: 2.7618 - dense_3_acc: 0.0916 - dense_3_acc_1: 0.4431 - dense_3_acc_2: 0.1729 - dense_3_acc_3: 0.0616 - dense_3_acc_4: 0.7884 - dense_3_acc_5: 0.1063 - dense_3_acc_6: 0.0092 - dense_3_acc_7: 0.8688 - dense_3_acc_8: 0.0804 - dense_3_acc_9: 0.05 - ETA: 12s - loss: 20.4375 - dense_3_loss: 2.7616 - dense_3_acc: 0.1034 - dense_3_acc_1: 0.4478 - dense_3_acc_2: 0.1728 - dense_3_acc_3: 0.0604 - dense_3_acc_4: 0.7926 - dense_3_acc_5: 0.1042 - dense_3_acc_6: 0.0090 - dense_3_acc_7: 0.8714 - dense_3_acc_8: 0.0836 - dense_3_acc_9: 0.05 - ETA: 12s - loss: 20.3865 - dense_3_loss: 2.7598 - dense_3_acc: 0.1151 - dense_3_acc_1: 0.4527 - dense_3_acc_2: 0.1749 - dense_3_acc_3: 0.0600 - dense_3_acc_4: 0.7967 - dense_3_acc_5: 0.1022 - dense_3_acc_6: 0.0088 - dense_3_acc_7: 0.8739 - dense_3_acc_8: 0.0835 - dense_3_acc_9: 0.05 - ETA: 11s - loss: 20.3390 - dense_3_loss: 2.7599 - dense_3_acc: 0.1248 - dense_3_acc_1: 0.4560 - dense_3_acc_2: 0.1748 - dense_3_acc_3: 0.0598 - dense_3_acc_4: 0.8006 - dense_3_acc_5: 0.1002 - dense_3_acc_6: 0.0087 - dense_3_acc_7: 0.8762 - dense_3_acc_8: 0.0850 - dense_3_acc_9: 0.05 - ETA: 11s - loss: 20.2916 - dense_3_loss: 2.7576 - dense_3_acc: 0.1340 - dense_3_acc_1: 0.4589 - dense_3_acc_2: 0.1755 - dense_3_acc_3: 0.0596 - dense_3_acc_4: 0.8043 - dense_3_acc_5: 0.0983 - dense_3_acc_6: 0.0085 - dense_3_acc_7: 0.8757 - dense_3_acc_8: 0.0889 - dense_3_acc_9: 0.05 - ETA: 11s - loss: 20.2454 - dense_3_loss: 2.7563 - dense_3_acc: 0.1419 - dense_3_acc_1: 0.4607 - dense_3_acc_2: 0.1748 - dense_3_acc_3: 0.0607 - dense_3_acc_4: 0.8080 - dense_3_acc_5: 0.0965 - dense_3_acc_6: 0.0083 - dense_3_acc_7: 0.8780 - dense_3_acc_8: 0.0883 - dense_3_acc_9: 0.06 - ETA: 10s - loss: 20.1933 - dense_3_loss: 2.7549 - dense_3_acc: 0.1513 - dense_3_acc_1: 0.4644 - dense_3_acc_2: 0.1762 - dense_3_acc_3: 0.0598 - dense_3_acc_4: 0.8115 - dense_3_acc_5: 0.0947 - dense_3_acc_6: 0.0082 - dense_3_acc_7: 0.8800 - dense_3_acc_8: 0.0918 - dense_3_acc_9: 0.06 - ETA: 10s - loss: 20.1366 - dense_3_loss: 2.7523 - dense_3_acc: 0.1609 - dense_3_acc_1: 0.4684 - dense_3_acc_2: 0.1771 - dense_3_acc_3: 0.0587 - dense_3_acc_4: 0.8148 - dense_3_acc_5: 0.0930 - dense_3_acc_6: 0.0080 - dense_3_acc_7: 0.8821 - dense_3_acc_8: 0.0959 - dense_3_acc_9: 0.06 - ETA: 9s - loss: 20.0821 - dense_3_loss: 2.7506 - dense_3_acc: 0.1700 - dense_3_acc_1: 0.4721 - dense_3_acc_2: 0.1781 - dense_3_acc_3: 0.0589 - dense_3_acc_4: 0.8181 - dense_3_acc_5: 0.0914 - dense_3_acc_6: 0.0079 - dense_3_acc_7: 0.8842 - dense_3_acc_8: 0.0949 - dense_3_acc_9: 0.0639 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8600/10000 [========================>.....] - ETA: 9s - loss: 20.0264 - dense_3_loss: 2.7482 - dense_3_acc: 0.1781 - dense_3_acc_1: 0.4750 - dense_3_acc_2: 0.1772 - dense_3_acc_3: 0.0584 - dense_3_acc_4: 0.8212 - dense_3_acc_5: 0.0900 - dense_3_acc_6: 0.0086 - dense_3_acc_7: 0.8833 - dense_3_acc_8: 0.0997 - dense_3_acc_9: 0.064 - ETA: 9s - loss: 19.9726 - dense_3_loss: 2.7446 - dense_3_acc: 0.1844 - dense_3_acc_1: 0.4763 - dense_3_acc_2: 0.1778 - dense_3_acc_3: 0.0581 - dense_3_acc_4: 0.8242 - dense_3_acc_5: 0.0893 - dense_3_acc_6: 0.0090 - dense_3_acc_7: 0.8839 - dense_3_acc_8: 0.1032 - dense_3_acc_9: 0.065 - ETA: 8s - loss: 19.9162 - dense_3_loss: 2.7415 - dense_3_acc: 0.1900 - dense_3_acc_1: 0.4770 - dense_3_acc_2: 0.1782 - dense_3_acc_3: 0.0580 - dense_3_acc_4: 0.8272 - dense_3_acc_5: 0.0878 - dense_3_acc_6: 0.0090 - dense_3_acc_7: 0.8858 - dense_3_acc_8: 0.1027 - dense_3_acc_9: 0.067 - ETA: 8s - loss: 19.8532 - dense_3_loss: 2.7369 - dense_3_acc: 0.1966 - dense_3_acc_1: 0.4789 - dense_3_acc_2: 0.1830 - dense_3_acc_3: 0.0570 - dense_3_acc_4: 0.8300 - dense_3_acc_5: 0.0939 - dense_3_acc_6: 0.0089 - dense_3_acc_7: 0.8877 - dense_3_acc_8: 0.1061 - dense_3_acc_9: 0.068 - ETA: 8s - loss: 19.7964 - dense_3_loss: 2.7336 - dense_3_acc: 0.2016 - dense_3_acc_1: 0.4794 - dense_3_acc_2: 0.1856 - dense_3_acc_3: 0.0566 - dense_3_acc_4: 0.8327 - dense_3_acc_5: 0.1055 - dense_3_acc_6: 0.0094 - dense_3_acc_7: 0.8895 - dense_3_acc_8: 0.1084 - dense_3_acc_9: 0.069 - ETA: 7s - loss: 19.7358 - dense_3_loss: 2.7315 - dense_3_acc: 0.2079 - dense_3_acc_1: 0.4813 - dense_3_acc_2: 0.1894 - dense_3_acc_3: 0.0570 - dense_3_acc_4: 0.8354 - dense_3_acc_5: 0.1171 - dense_3_acc_6: 0.0100 - dense_3_acc_7: 0.8913 - dense_3_acc_8: 0.1124 - dense_3_acc_9: 0.069 - ETA: 7s - loss: 19.6748 - dense_3_loss: 2.7290 - dense_3_acc: 0.2142 - dense_3_acc_1: 0.4833 - dense_3_acc_2: 0.1906 - dense_3_acc_3: 0.0564 - dense_3_acc_4: 0.8380 - dense_3_acc_5: 0.1284 - dense_3_acc_6: 0.0114 - dense_3_acc_7: 0.8928 - dense_3_acc_8: 0.1163 - dense_3_acc_9: 0.069 - ETA: 7s - loss: 19.6072 - dense_3_loss: 2.7276 - dense_3_acc: 0.2211 - dense_3_acc_1: 0.4860 - dense_3_acc_2: 0.1931 - dense_3_acc_3: 0.0569 - dense_3_acc_4: 0.8405 - dense_3_acc_5: 0.1395 - dense_3_acc_6: 0.0128 - dense_3_acc_7: 0.8945 - dense_3_acc_8: 0.1191 - dense_3_acc_9: 0.070 - ETA: 7s - loss: 19.5360 - dense_3_loss: 2.7212 - dense_3_acc: 0.2273 - dense_3_acc_1: 0.4882 - dense_3_acc_2: 0.1952 - dense_3_acc_3: 0.0561 - dense_3_acc_4: 0.8429 - dense_3_acc_5: 0.1497 - dense_3_acc_6: 0.0130 - dense_3_acc_7: 0.8961 - dense_3_acc_8: 0.1227 - dense_3_acc_9: 0.070 - ETA: 6s - loss: 19.4668 - dense_3_loss: 2.7149 - dense_3_acc: 0.2327 - dense_3_acc_1: 0.4897 - dense_3_acc_2: 0.1976 - dense_3_acc_3: 0.0552 - dense_3_acc_4: 0.8452 - dense_3_acc_5: 0.1601 - dense_3_acc_6: 0.0137 - dense_3_acc_7: 0.8976 - dense_3_acc_8: 0.1261 - dense_3_acc_9: 0.072 - ETA: 6s - loss: 19.3979 - dense_3_loss: 2.7130 - dense_3_acc: 0.2387 - dense_3_acc_1: 0.4919 - dense_3_acc_2: 0.1987 - dense_3_acc_3: 0.0553 - dense_3_acc_4: 0.8475 - dense_3_acc_5: 0.1703 - dense_3_acc_6: 0.0146 - dense_3_acc_7: 0.8991 - dense_3_acc_8: 0.1303 - dense_3_acc_9: 0.072 - ETA: 6s - loss: 19.3269 - dense_3_loss: 2.7088 - dense_3_acc: 0.2433 - dense_3_acc_1: 0.4929 - dense_3_acc_2: 0.1994 - dense_3_acc_3: 0.0545 - dense_3_acc_4: 0.8497 - dense_3_acc_5: 0.1809 - dense_3_acc_6: 0.0154 - dense_3_acc_7: 0.9006 - dense_3_acc_8: 0.1355 - dense_3_acc_9: 0.072 - ETA: 6s - loss: 19.2542 - dense_3_loss: 2.7033 - dense_3_acc: 0.2481 - dense_3_acc_1: 0.4941 - dense_3_acc_2: 0.2017 - dense_3_acc_3: 0.0537 - dense_3_acc_4: 0.8519 - dense_3_acc_5: 0.1907 - dense_3_acc_6: 0.0163 - dense_3_acc_7: 0.9020 - dense_3_acc_8: 0.1384 - dense_3_acc_9: 0.074 - ETA: 5s - loss: 19.1808 - dense_3_loss: 2.6994 - dense_3_acc: 0.2527 - dense_3_acc_1: 0.4952 - dense_3_acc_2: 0.2025 - dense_3_acc_3: 0.0539 - dense_3_acc_4: 0.8539 - dense_3_acc_5: 0.1985 - dense_3_acc_6: 0.0175 - dense_3_acc_7: 0.9034 - dense_3_acc_8: 0.1432 - dense_3_acc_9: 0.074 - ETA: 5s - loss: 19.1071 - dense_3_loss: 2.6947 - dense_3_acc: 0.2579 - dense_3_acc_1: 0.4971 - dense_3_acc_2: 0.2039 - dense_3_acc_3: 0.0539 - dense_3_acc_4: 0.8560 - dense_3_acc_5: 0.2072 - dense_3_acc_6: 0.0181 - dense_3_acc_7: 0.9047 - dense_3_acc_8: 0.1467 - dense_3_acc_9: 0.074 - ETA: 5s - loss: 19.0293 - dense_3_loss: 2.6900 - dense_3_acc: 0.2627 - dense_3_acc_1: 0.4986 - dense_3_acc_2: 0.2053 - dense_3_acc_3: 0.0538 - dense_3_acc_4: 0.8579 - dense_3_acc_5: 0.2163 - dense_3_acc_6: 0.0190 - dense_3_acc_7: 0.9060 - dense_3_acc_8: 0.1504 - dense_3_acc_9: 0.074 - ETA: 5s - loss: 18.9511 - dense_3_loss: 2.6844 - dense_3_acc: 0.2676 - dense_3_acc_1: 0.5004 - dense_3_acc_2: 0.2069 - dense_3_acc_3: 0.0536 - dense_3_acc_4: 0.8599 - dense_3_acc_5: 0.2247 - dense_3_acc_6: 0.0197 - dense_3_acc_7: 0.9073 - dense_3_acc_8: 0.1546 - dense_3_acc_9: 0.075 - ETA: 4s - loss: 18.8714 - dense_3_loss: 2.6796 - dense_3_acc: 0.2725 - dense_3_acc_1: 0.5023 - dense_3_acc_2: 0.2091 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.8617 - dense_3_acc_5: 0.2328 - dense_3_acc_6: 0.0213 - dense_3_acc_7: 0.9085 - dense_3_acc_8: 0.1576 - dense_3_acc_9: 0.075 - ETA: 4s - loss: 18.7956 - dense_3_loss: 2.6744 - dense_3_acc: 0.2759 - dense_3_acc_1: 0.5028 - dense_3_acc_2: 0.2095 - dense_3_acc_3: 0.0570 - dense_3_acc_4: 0.8636 - dense_3_acc_5: 0.2413 - dense_3_acc_6: 0.0221 - dense_3_acc_7: 0.9097 - dense_3_acc_8: 0.1607 - dense_3_acc_9: 0.076 - ETA: 4s - loss: 18.7159 - dense_3_loss: 2.6698 - dense_3_acc: 0.2804 - dense_3_acc_1: 0.5047 - dense_3_acc_2: 0.2121 - dense_3_acc_3: 0.0578 - dense_3_acc_4: 0.8653 - dense_3_acc_5: 0.2484 - dense_3_acc_6: 0.0231 - dense_3_acc_7: 0.9109 - dense_3_acc_8: 0.1643 - dense_3_acc_9: 0.077 - ETA: 4s - loss: 18.6388 - dense_3_loss: 2.6650 - dense_3_acc: 0.2845 - dense_3_acc_1: 0.5071 - dense_3_acc_2: 0.2146 - dense_3_acc_3: 0.0578 - dense_3_acc_4: 0.8671 - dense_3_acc_5: 0.2559 - dense_3_acc_6: 0.0233 - dense_3_acc_7: 0.9121 - dense_3_acc_8: 0.1667 - dense_3_acc_9: 0.077 - ETA: 3s - loss: 18.5607 - dense_3_loss: 2.6605 - dense_3_acc: 0.2880 - dense_3_acc_1: 0.5095 - dense_3_acc_2: 0.2167 - dense_3_acc_3: 0.0581 - dense_3_acc_4: 0.8687 - dense_3_acc_5: 0.2634 - dense_3_acc_6: 0.0242 - dense_3_acc_7: 0.9132 - dense_3_acc_8: 0.1697 - dense_3_acc_9: 0.078 - ETA: 3s - loss: 18.4836 - dense_3_loss: 2.6561 - dense_3_acc: 0.2915 - dense_3_acc_1: 0.5116 - dense_3_acc_2: 0.2190 - dense_3_acc_3: 0.0586 - dense_3_acc_4: 0.8704 - dense_3_acc_5: 0.2708 - dense_3_acc_6: 0.0255 - dense_3_acc_7: 0.9143 - dense_3_acc_8: 0.1720 - dense_3_acc_9: 0.078 - ETA: 3s - loss: 18.4084 - dense_3_loss: 2.6520 - dense_3_acc: 0.2964 - dense_3_acc_1: 0.5156 - dense_3_acc_2: 0.2207 - dense_3_acc_3: 0.0591 - dense_3_acc_4: 0.8720 - dense_3_acc_5: 0.2774 - dense_3_acc_6: 0.0272 - dense_3_acc_7: 0.9153 - dense_3_acc_8: 0.1746 - dense_3_acc_9: 0.079 - ETA: 3s - loss: 18.3317 - dense_3_loss: 2.6478 - dense_3_acc: 0.2998 - dense_3_acc_1: 0.5176 - dense_3_acc_2: 0.2232 - dense_3_acc_3: 0.0600 - dense_3_acc_4: 0.8735 - dense_3_acc_5: 0.2846 - dense_3_acc_6: 0.0280 - dense_3_acc_7: 0.9163 - dense_3_acc_8: 0.1777 - dense_3_acc_9: 0.080 - ETA: 3s - loss: 18.2558 - dense_3_loss: 2.6435 - dense_3_acc: 0.3040 - dense_3_acc_1: 0.5201 - dense_3_acc_2: 0.2247 - dense_3_acc_3: 0.0606 - dense_3_acc_4: 0.8751 - dense_3_acc_5: 0.2913 - dense_3_acc_6: 0.0292 - dense_3_acc_7: 0.9173 - dense_3_acc_8: 0.1801 - dense_3_acc_9: 0.080 - ETA: 2s - loss: 18.1835 - dense_3_loss: 2.6392 - dense_3_acc: 0.3075 - dense_3_acc_1: 0.5218 - dense_3_acc_2: 0.2251 - dense_3_acc_3: 0.0612 - dense_3_acc_4: 0.8765 - dense_3_acc_5: 0.2974 - dense_3_acc_6: 0.0310 - dense_3_acc_7: 0.9183 - dense_3_acc_8: 0.1835 - dense_3_acc_9: 0.081 - ETA: 2s - loss: 18.1092 - dense_3_loss: 2.6348 - dense_3_acc: 0.3113 - dense_3_acc_1: 0.5242 - dense_3_acc_2: 0.2267 - dense_3_acc_3: 0.0618 - dense_3_acc_4: 0.8780 - dense_3_acc_5: 0.3039 - dense_3_acc_6: 0.0320 - dense_3_acc_7: 0.9193 - dense_3_acc_8: 0.1859 - dense_3_acc_9: 0.082 - ETA: 2s - loss: 18.0346 - dense_3_loss: 2.6303 - dense_3_acc: 0.3150 - dense_3_acc_1: 0.5279 - dense_3_acc_2: 0.2283 - dense_3_acc_3: 0.0634 - dense_3_acc_4: 0.8794 - dense_3_acc_5: 0.3106 - dense_3_acc_6: 0.0338 - dense_3_acc_7: 0.9202 - dense_3_acc_8: 0.1881 - dense_3_acc_9: 0.0829"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 2s - loss: 17.9622 - dense_3_loss: 2.6256 - dense_3_acc: 0.3177 - dense_3_acc_1: 0.5313 - dense_3_acc_2: 0.2301 - dense_3_acc_3: 0.0639 - dense_3_acc_4: 0.8808 - dense_3_acc_5: 0.3164 - dense_3_acc_6: 0.0354 - dense_3_acc_7: 0.9211 - dense_3_acc_8: 0.1913 - dense_3_acc_9: 0.084 - ETA: 2s - loss: 17.8907 - dense_3_loss: 2.6213 - dense_3_acc: 0.3215 - dense_3_acc_1: 0.5345 - dense_3_acc_2: 0.2307 - dense_3_acc_3: 0.0653 - dense_3_acc_4: 0.8822 - dense_3_acc_5: 0.3226 - dense_3_acc_6: 0.0366 - dense_3_acc_7: 0.9220 - dense_3_acc_8: 0.1930 - dense_3_acc_9: 0.085 - ETA: 1s - loss: 17.8199 - dense_3_loss: 2.6174 - dense_3_acc: 0.3247 - dense_3_acc_1: 0.5375 - dense_3_acc_2: 0.2317 - dense_3_acc_3: 0.0658 - dense_3_acc_4: 0.8835 - dense_3_acc_5: 0.3288 - dense_3_acc_6: 0.0385 - dense_3_acc_7: 0.9229 - dense_3_acc_8: 0.1949 - dense_3_acc_9: 0.086 - ETA: 1s - loss: 17.7526 - dense_3_loss: 2.6134 - dense_3_acc: 0.3280 - dense_3_acc_1: 0.5401 - dense_3_acc_2: 0.2341 - dense_3_acc_3: 0.0662 - dense_3_acc_4: 0.8848 - dense_3_acc_5: 0.3348 - dense_3_acc_6: 0.0403 - dense_3_acc_7: 0.9238 - dense_3_acc_8: 0.1967 - dense_3_acc_9: 0.087 - ETA: 1s - loss: 17.6840 - dense_3_loss: 2.6105 - dense_3_acc: 0.3313 - dense_3_acc_1: 0.5429 - dense_3_acc_2: 0.2364 - dense_3_acc_3: 0.0665 - dense_3_acc_4: 0.8860 - dense_3_acc_5: 0.3409 - dense_3_acc_6: 0.0425 - dense_3_acc_7: 0.9246 - dense_3_acc_8: 0.1996 - dense_3_acc_9: 0.088 - ETA: 1s - loss: 17.6146 - dense_3_loss: 2.6059 - dense_3_acc: 0.3350 - dense_3_acc_1: 0.5464 - dense_3_acc_2: 0.2376 - dense_3_acc_3: 0.0680 - dense_3_acc_4: 0.8873 - dense_3_acc_5: 0.3459 - dense_3_acc_6: 0.0458 - dense_3_acc_7: 0.9254 - dense_3_acc_8: 0.2016 - dense_3_acc_9: 0.089 - ETA: 1s - loss: 17.5451 - dense_3_loss: 2.6018 - dense_3_acc: 0.3376 - dense_3_acc_1: 0.5488 - dense_3_acc_2: 0.2390 - dense_3_acc_3: 0.0686 - dense_3_acc_4: 0.8885 - dense_3_acc_5: 0.3511 - dense_3_acc_6: 0.0489 - dense_3_acc_7: 0.9262 - dense_3_acc_8: 0.2038 - dense_3_acc_9: 0.091 - ETA: 1s - loss: 17.4791 - dense_3_loss: 2.5979 - dense_3_acc: 0.3395 - dense_3_acc_1: 0.5517 - dense_3_acc_2: 0.2407 - dense_3_acc_3: 0.0691 - dense_3_acc_4: 0.8897 - dense_3_acc_5: 0.3565 - dense_3_acc_6: 0.0509 - dense_3_acc_7: 0.9270 - dense_3_acc_8: 0.2057 - dense_3_acc_9: 0.091 - ETA: 0s - loss: 17.4125 - dense_3_loss: 2.5947 - dense_3_acc: 0.3423 - dense_3_acc_1: 0.5549 - dense_3_acc_2: 0.2427 - dense_3_acc_3: 0.0698 - dense_3_acc_4: 0.8908 - dense_3_acc_5: 0.3621 - dense_3_acc_6: 0.0528 - dense_3_acc_7: 0.9278 - dense_3_acc_8: 0.2076 - dense_3_acc_9: 0.092 - ETA: 0s - loss: 17.3446 - dense_3_loss: 2.5906 - dense_3_acc: 0.3451 - dense_3_acc_1: 0.5578 - dense_3_acc_2: 0.2449 - dense_3_acc_3: 0.0710 - dense_3_acc_4: 0.8920 - dense_3_acc_5: 0.3679 - dense_3_acc_6: 0.0553 - dense_3_acc_7: 0.9285 - dense_3_acc_8: 0.2102 - dense_3_acc_9: 0.093 - ETA: 0s - loss: 17.2798 - dense_3_loss: 2.5866 - dense_3_acc: 0.3482 - dense_3_acc_1: 0.5608 - dense_3_acc_2: 0.2468 - dense_3_acc_3: 0.0713 - dense_3_acc_4: 0.8931 - dense_3_acc_5: 0.3733 - dense_3_acc_6: 0.0570 - dense_3_acc_7: 0.9293 - dense_3_acc_8: 0.2124 - dense_3_acc_9: 0.094 - ETA: 0s - loss: 17.2135 - dense_3_loss: 2.5820 - dense_3_acc: 0.3514 - dense_3_acc_1: 0.5645 - dense_3_acc_2: 0.2490 - dense_3_acc_3: 0.0720 - dense_3_acc_4: 0.8942 - dense_3_acc_5: 0.3781 - dense_3_acc_6: 0.0589 - dense_3_acc_7: 0.9300 - dense_3_acc_8: 0.2147 - dense_3_acc_9: 0.096 - ETA: 0s - loss: 17.1494 - dense_3_loss: 2.5789 - dense_3_acc: 0.3540 - dense_3_acc_1: 0.5675 - dense_3_acc_2: 0.2512 - dense_3_acc_3: 0.0728 - dense_3_acc_4: 0.8953 - dense_3_acc_5: 0.3829 - dense_3_acc_6: 0.0602 - dense_3_acc_7: 0.9307 - dense_3_acc_8: 0.2176 - dense_3_acc_9: 0.097 - 16s 2ms/step - loss: 17.0833 - dense_3_loss: 2.5755 - dense_3_acc: 0.3568 - dense_3_acc_1: 0.5711 - dense_3_acc_2: 0.2530 - dense_3_acc_3: 0.0732 - dense_3_acc_4: 0.8963 - dense_3_acc_5: 0.3879 - dense_3_acc_6: 0.0629 - dense_3_acc_7: 0.9314 - dense_3_acc_8: 0.2191 - dense_3_acc_9: 0.0981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2557329b7f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model that was trained longer\n",
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "source: 5 April 09\n",
      "output: 2009-05-05\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))[np.newaxis,...]\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
